# Patent AI Agent - Keyword Extraction System

An AI-powered patent keyword extraction system with modular architecture for patent prior art search and analysis.

## ğŸ—ï¸ Project Architecture

```
priorart_p/
â”œâ”€â”€ src/                           # Core source code
â”‚   â”œâ”€â”€ core/                      # Main AI agent modules
â”‚   â”‚   â”œâ”€â”€ extractor.py           # CoreConceptExtractor main class
â”‚   â”‚   â”œâ”€â”€ mock_extractor.py      # Mock version for testing/demo
â”‚   â”‚   â”œâ”€â”€ enhanced_mock_extractor.py # Enhanced mock version
â”‚   â”‚   â””â”€â”€ standalone_mock_extractor.py # Standalone demo
â”‚   â”œâ”€â”€ api/                       # External API integrations
â”‚   â”‚   â””â”€â”€ ipc_classifier.py      # IPC/CPC classification API
â”‚   â”œâ”€â”€ crawling/                  # Web scraping modules
â”‚   â”‚   â””â”€â”€ patent_crawler.py      # Google Patents crawler
â”‚   â”œâ”€â”€ evaluation/                # Similarity and evaluation
â”‚   â”‚   â””â”€â”€ similarity_evaluator.py # Text similarity scoring
â”‚   â”œâ”€â”€ prompts/                   # Prompt management
â”‚   â”‚   â””â”€â”€ extraction_prompts.py  # LLM prompt templates
â”‚   â””â”€â”€ utils/                     # Utility functions
â”œâ”€â”€ config/                        # Configuration
â”‚   â””â”€â”€ settings.py               # Settings and API keys
â”œâ”€â”€ static/                       # Web interface assets
â”‚   â”œâ”€â”€ index.html                # Web UI homepage
â”‚   â””â”€â”€ app.js                    # Frontend JavaScript
â”œâ”€â”€ main.py                       # Command-line entry point
â”œâ”€â”€ app.py                        # FastAPI backend server
â”œâ”€â”€ streamlit_app.py              # Real Streamlit web interface
â”œâ”€â”€ streamlit_demo_app.py         # Demo Streamlit interface (mock)
â”œâ”€â”€ run_patent_agent.py           # Unified launcher script
â”œâ”€â”€ run_*.py                      # Various interface launchers
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This documentation
```

## ğŸš€ Key Features

### 1. **AI-Powered Patent Keyword Extraction** (`src/core/`)
- **LangGraph Workflow**: Multi-step extraction pipeline with state management
- **8-Phase Process**: Input normalization â†’ Concept extraction â†’ Keyword generation â†’ Human validation â†’ Synonym expansion â†’ Query generation â†’ URL discovery â†’ Relevance evaluation
- **Human-in-the-Loop**: Interactive approve/reject/edit workflow
- **Multiple Interfaces**: Command-line, web UI, and demo modes

### 2. **External API Integration** (`src/api/`)
- **IPC Classification**: International Patent Classification via WIPO API
- **Brave Search**: Patent URL discovery through web search
- **Tavily Search**: Additional research and synonym expansion

### 3. **Web Scraping & Data Collection** (`src/crawling/`)
- **Google Patents Crawler**: Extract title, abstract, claims, and descriptions
- **Error Handling**: Robust retry logic and exception handling
- **Content Parsing**: Structured data extraction from patent pages

### 4. **Similarity & Evaluation** (`src/evaluation/`)
- **Semantic Similarity**: Using sentence transformers for text comparison
- **Relevance Scoring**: LLM-based evaluation of patent relevance
- **Multi-metric Analysis**: Scenario and problem relevance scoring

### 5. **Prompt Engineering** (`src/prompts/`)
- **Structured Templates**: Pydantic-based prompt management
- **JSON Output Parsing**: Reliable structured data extraction
- **Context-Aware Prompts**: Dynamic prompt generation based on workflow state

## ğŸ“¦ Installation

```bash
# Clone repository
git clone https://github.com/chienthan2vn/priorart_p.git
cd priorart_p

# Install dependencies
pip install -r requirements.txt

# Set up environment variables (optional)
cp .env.example .env
# Edit .env with your API keys
```

## ğŸ® Usage Options

### ğŸ­ Demo Mode - Recommended for Testing & Demos

```bash
# No LLM infrastructure required - uses mock responses
python run_demo.py
# OR
streamlit run streamlit_demo_app.py --server.port=8502
```

**ğŸ¯ Demo Mode Features:**
- **ğŸ­ Mock LLM**: No Ollama or API keys needed
- **ğŸ“ Complete Workflow**: Full extraction pipeline simulation
- **ğŸ¯ Real Interaction**: Actual human evaluation (approve/reject/edit)
- **ğŸ“Š Full Results**: Complete results with export functionality
- **âš¡ Instant Setup**: Run immediately without configuration

ğŸ‘‰ **See demo guide**: [DEMO_README.md](DEMO_README.md)

### ğŸŒ Web Interface (Real LLM)

```bash
# Method 1: Using launcher script
python run_streamlit.py

# Method 2: Direct Streamlit command
streamlit run streamlit_app.py
```

**ğŸ¯ Web Interface Features:**
- **ğŸ¤– Real AI**: Actual LLM processing with Ollama
- **ğŸ“ Input Processing**: Patent idea description input
- **ğŸ¯ Interactive Evaluation**: Three interaction choices:
  - âœ… **Approve**: Accept keywords and continue
  - âŒ **Reject**: Reject and restart with feedback
  - âœï¸ **Edit**: Manually modify keywords
- **ğŸ“Š Visual Results**: Tabbed results display
- **ğŸ’¾ Export Options**: JSON/CSV export for further analysis

ğŸ‘‰ **Detailed guide**: [STREAMLIT_README.md](STREAMLIT_README.md)

### ğŸš€ Unified Interface Launcher

```bash
# Choose interface from interactive menu
python run_patent_agent.py
```

### ğŸ’» Command Line Interface

```bash
python main.py
```

### ğŸŒ FastAPI Backend Server

```bash
# Start REST API server
python app.py
# OR
uvicorn app:app --host 0.0.0.0 --port 8000
```

### ğŸ“š Module Usage Examples

```python
from src.core.extractor import CoreConceptExtractor

# Initialize the extractor
extractor = CoreConceptExtractor(model_name="qwen2.5:3b-instruct")

# Run keyword extraction
results = extractor.extract_keywords(your_patent_text)
```

### ğŸ”Œ API Module Usage

```python
# IPC Classification
from src.api.ipc_classifier import get_ipc_predictions
predictions = get_ipc_predictions("your patent summary")

# Patent Crawling
from src.crawling.patent_crawler import lay_thong_tin_patent
patent_info = lay_thong_tin_patent("https://patents.google.com/patent/...")

# Similarity Evaluation
from src.evaluation.similarity_evaluator import PatentSimilarityEvaluator
evaluator = PatentSimilarityEvaluator()
scores = evaluator.evaluate_similarity(text1, text2)
```

## âš™ï¸ Configuration

All configuration is managed in `config/settings.py`:

```python
from config.settings import settings

# Access settings
print(settings.DEFAULT_MODEL_NAME)
print(settings.MAX_SEARCH_RESULTS)

# Validate API keys
validation = settings.validate_api_keys()
```

## ğŸ§ª Testing

```bash
# Run individual module tests
python test_mock_core.py           # Test mock extraction system
python test_streamlit_integration.py  # Test Streamlit integration
python test_mock_demo.py           # Test demo interface

# Test module imports
python -c "from src.core.extractor import CoreConceptExtractor; print('Core module OK')"
python -c "from src.api.ipc_classifier import get_ipc_predictions; print('API module OK')"
```

## ğŸ“‹ Detailed Workflow

### 1. **Input Normalization Phase**
- Input: Raw patent idea text
- Output: Structured problem and technical components

### 2. **Concept Extraction Phase** 
- Input: Normalized text
- Output: Concept Matrix (Problem/Purpose, Object/System, Environment/Field)

### 3. **Keyword Generation Phase**
- Input: Concept Matrix
- Output: Seed keywords for each concept category

### 4. **Human Evaluation Phase**
- User choices: Approve, Reject, or Edit keywords
- Interactive interface (CLI/Web/Demo)
- Feedback incorporation for iterative improvement

### 5. **Synonym Expansion Phase**
- Automated keyword expansion via web search
- Generate synonyms and related terms
- Context-aware term extraction

### 6. **Query Generation Phase**
- Create Boolean search queries for patent databases
- Integrate IPC/CPC classification codes
- Optimize search string construction

### 7. **Patent URL Discovery Phase**
- Search for relevant patents using Brave Search API
- Target Google Patents specifically
- Collect candidate patent URLs

### 8. **Relevance Evaluation Phase**
- Extract patent content from URLs
- Score relevance using LLM evaluation
- Rank results by scenario and problem relevance

## ğŸ”§ Core Dependencies

- **LangChain & LangGraph**: LLM application framework and workflow orchestration
- **Ollama**: Local LLM server for AI processing
- **Pydantic**: Data validation and structured output parsing
- **Streamlit**: Web interface framework
- **FastAPI**: REST API backend server
- **Sentence-Transformers**: Semantic similarity analysis
- **BeautifulSoup & Requests**: Web scraping and HTTP client
- **Transformers**: Hugging Face model integration

## ğŸ¯ Available Interfaces

| Interface | Description | Best For | Requirements |
|-----------|-------------|----------|-------------|
| **Demo Mode** | Mock LLM responses | Testing, presentations, training | Minimal - just Streamlit |
| **Streamlit Web** | Full web interface | Interactive usage, exploration | Ollama + API keys |
| **Command Line** | Terminal interface | Automation, scripting | Ollama + API keys |
| **FastAPI Backend** | REST API server | Integration, web apps | Full dependencies |
| **Unified Launcher** | Menu-driven selection | Choosing interfaces | None |

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Create Pull Request

## ğŸ“œ License

This project is distributed under the MIT License. See `LICENSE` file for details.

## ğŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/chienthan2vn/priorart_p/issues)
- **Documentation**: Reference the specialized README files:
  - [DEMO_README.md](DEMO_README.md) - Demo mode guide
  - [STREAMLIT_README.md](STREAMLIT_README.md) - Web interface guide
  - [WEB_APP_README.md](WEB_APP_README.md) - FastAPI backend guide

---

**Note**: This modular architecture is optimized for maintainability, extensibility, and testing. Each module has clear responsibilities and can be used independently or as part of the complete system.
